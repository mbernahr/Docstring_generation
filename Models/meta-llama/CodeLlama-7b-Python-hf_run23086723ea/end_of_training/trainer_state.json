{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7712082262210797,
  "eval_steps": 100,
  "global_step": 1200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006426735218508998,
      "grad_norm": 14.639098167419434,
      "learning_rate": 1.9444444444444442e-05,
      "loss": 0.7246,
      "step": 10
    },
    {
      "epoch": 0.012853470437017995,
      "grad_norm": 4.5756707191467285,
      "learning_rate": 3.8888888888888884e-05,
      "loss": 0.8081,
      "step": 20
    },
    {
      "epoch": 0.019280205655526992,
      "grad_norm": 4.761199951171875,
      "learning_rate": 5.833333333333333e-05,
      "loss": 0.8618,
      "step": 30
    },
    {
      "epoch": 0.02570694087403599,
      "grad_norm": 7.6623334884643555,
      "learning_rate": 6.640783086353596e-05,
      "loss": 0.824,
      "step": 40
    },
    {
      "epoch": 0.032133676092544985,
      "grad_norm": 71.72986602783203,
      "learning_rate": 5.939696961966999e-05,
      "loss": 0.8891,
      "step": 50
    },
    {
      "epoch": 0.038560411311053984,
      "grad_norm": 16.93743324279785,
      "learning_rate": 5.4221766846903836e-05,
      "loss": 0.5938,
      "step": 60
    },
    {
      "epoch": 0.04498714652956298,
      "grad_norm": 14.045249938964844,
      "learning_rate": 5.019960159204453e-05,
      "loss": 0.6912,
      "step": 70
    },
    {
      "epoch": 0.05141388174807198,
      "grad_norm": 40.55514144897461,
      "learning_rate": 4.695742752749558e-05,
      "loss": 0.802,
      "step": 80
    },
    {
      "epoch": 0.05784061696658098,
      "grad_norm": 32.58083724975586,
      "learning_rate": 4.4271887242357305e-05,
      "loss": 0.7633,
      "step": 90
    },
    {
      "epoch": 0.06426735218508997,
      "grad_norm": 7.4723639488220215,
      "learning_rate": 4.2e-05,
      "loss": 0.8662,
      "step": 100
    },
    {
      "epoch": 0.06426735218508997,
      "eval_loss": 0.7406915426254272,
      "eval_runtime": 2054.4006,
      "eval_samples_per_second": 1.954,
      "eval_steps_per_second": 0.244,
      "step": 100
    },
    {
      "epoch": 0.07069408740359898,
      "grad_norm": 2.3258016109466553,
      "learning_rate": 4.004542874831488e-05,
      "loss": 0.6456,
      "step": 110
    },
    {
      "epoch": 0.07712082262210797,
      "grad_norm": 2.020599842071533,
      "learning_rate": 3.834057902536162e-05,
      "loss": 0.7217,
      "step": 120
    },
    {
      "epoch": 0.08354755784061697,
      "grad_norm": 2.9012463092803955,
      "learning_rate": 3.683643681089522e-05,
      "loss": 0.7188,
      "step": 130
    },
    {
      "epoch": 0.08997429305912596,
      "grad_norm": 4.822697162628174,
      "learning_rate": 3.5496478698597695e-05,
      "loss": 0.7402,
      "step": 140
    },
    {
      "epoch": 0.09640102827763496,
      "grad_norm": 7.007784366607666,
      "learning_rate": 3.429285639896449e-05,
      "loss": 0.8247,
      "step": 150
    },
    {
      "epoch": 0.10282776349614396,
      "grad_norm": 2.3797836303710938,
      "learning_rate": 3.320391543176798e-05,
      "loss": 0.5812,
      "step": 160
    },
    {
      "epoch": 0.10925449871465295,
      "grad_norm": 1.8262048959732056,
      "learning_rate": 3.221252953158955e-05,
      "loss": 0.6039,
      "step": 170
    },
    {
      "epoch": 0.11568123393316196,
      "grad_norm": 3.5346789360046387,
      "learning_rate": 3.1304951684997054e-05,
      "loss": 0.75,
      "step": 180
    },
    {
      "epoch": 0.12210796915167095,
      "grad_norm": 2.893937587738037,
      "learning_rate": 3.047000250462049e-05,
      "loss": 0.7995,
      "step": 190
    },
    {
      "epoch": 0.12853470437017994,
      "grad_norm": 5.959937572479248,
      "learning_rate": 2.9698484809834994e-05,
      "loss": 0.8766,
      "step": 200
    },
    {
      "epoch": 0.12853470437017994,
      "eval_loss": 0.7207552790641785,
      "eval_runtime": 2077.7359,
      "eval_samples_per_second": 1.932,
      "eval_steps_per_second": 0.242,
      "step": 200
    },
    {
      "epoch": 0.13496143958868895,
      "grad_norm": 1.9806581735610962,
      "learning_rate": 2.8982753492378874e-05,
      "loss": 0.6316,
      "step": 210
    },
    {
      "epoch": 0.14138817480719795,
      "grad_norm": 1.570628046989441,
      "learning_rate": 2.8316394223456167e-05,
      "loss": 0.6992,
      "step": 220
    },
    {
      "epoch": 0.14781491002570693,
      "grad_norm": 3.4658539295196533,
      "learning_rate": 2.7693979882623055e-05,
      "loss": 0.7715,
      "step": 230
    },
    {
      "epoch": 0.15424164524421594,
      "grad_norm": 3.889641523361206,
      "learning_rate": 2.7110883423451918e-05,
      "loss": 0.7632,
      "step": 240
    },
    {
      "epoch": 0.16066838046272494,
      "grad_norm": 7.925483226776123,
      "learning_rate": 2.6563132345414385e-05,
      "loss": 0.8082,
      "step": 250
    },
    {
      "epoch": 0.16709511568123395,
      "grad_norm": 1.6491613388061523,
      "learning_rate": 2.6047294263733775e-05,
      "loss": 0.5836,
      "step": 260
    },
    {
      "epoch": 0.17352185089974292,
      "grad_norm": 1.8907054662704468,
      "learning_rate": 2.556038601690775e-05,
      "loss": 0.5985,
      "step": 270
    },
    {
      "epoch": 0.17994858611825193,
      "grad_norm": 3.1773107051849365,
      "learning_rate": 2.5099800796022265e-05,
      "loss": 0.7338,
      "step": 280
    },
    {
      "epoch": 0.18637532133676094,
      "grad_norm": 3.7041122913360596,
      "learning_rate": 2.4663249219617546e-05,
      "loss": 0.7544,
      "step": 290
    },
    {
      "epoch": 0.1928020565552699,
      "grad_norm": 5.645934104919434,
      "learning_rate": 2.4248711305964276e-05,
      "loss": 0.7591,
      "step": 300
    },
    {
      "epoch": 0.1928020565552699,
      "eval_loss": 0.710782527923584,
      "eval_runtime": 2048.0163,
      "eval_samples_per_second": 1.96,
      "eval_steps_per_second": 0.245,
      "step": 300
    },
    {
      "epoch": 0.19922879177377892,
      "grad_norm": 1.305256724357605,
      "learning_rate": 2.385439703837672e-05,
      "loss": 0.667,
      "step": 310
    },
    {
      "epoch": 0.20565552699228792,
      "grad_norm": 3.1261343955993652,
      "learning_rate": 2.347871376374779e-05,
      "loss": 0.6474,
      "step": 320
    },
    {
      "epoch": 0.2120822622107969,
      "grad_norm": 1.9382823705673218,
      "learning_rate": 2.312023906765357e-05,
      "loss": 0.6995,
      "step": 330
    },
    {
      "epoch": 0.2185089974293059,
      "grad_norm": 2.825943946838379,
      "learning_rate": 2.2777698070958896e-05,
      "loss": 0.6724,
      "step": 340
    },
    {
      "epoch": 0.2249357326478149,
      "grad_norm": 4.062124729156494,
      "learning_rate": 2.2449944320643645e-05,
      "loss": 0.7936,
      "step": 350
    },
    {
      "epoch": 0.23136246786632392,
      "grad_norm": 1.4294179677963257,
      "learning_rate": 2.2135943621178653e-05,
      "loss": 0.6479,
      "step": 360
    },
    {
      "epoch": 0.2377892030848329,
      "grad_norm": 1.8777750730514526,
      "learning_rate": 2.1834760286221524e-05,
      "loss": 0.7006,
      "step": 370
    },
    {
      "epoch": 0.2442159383033419,
      "grad_norm": 2.38224196434021,
      "learning_rate": 2.1545545393788235e-05,
      "loss": 0.7378,
      "step": 380
    },
    {
      "epoch": 0.2506426735218509,
      "grad_norm": 3.740504026412964,
      "learning_rate": 2.1267526708756994e-05,
      "loss": 0.7579,
      "step": 390
    },
    {
      "epoch": 0.2570694087403599,
      "grad_norm": 4.763982772827148,
      "learning_rate": 2.1e-05,
      "loss": 0.8032,
      "step": 400
    },
    {
      "epoch": 0.2570694087403599,
      "eval_loss": 0.7047936916351318,
      "eval_runtime": 2044.8501,
      "eval_samples_per_second": 1.963,
      "eval_steps_per_second": 0.245,
      "step": 400
    },
    {
      "epoch": 0.2634961439588689,
      "grad_norm": 1.2528401613235474,
      "learning_rate": 2.074232152964138e-05,
      "loss": 0.5384,
      "step": 410
    },
    {
      "epoch": 0.2699228791773779,
      "grad_norm": 2.0583157539367676,
      "learning_rate": 2.0493901531919198e-05,
      "loss": 0.7502,
      "step": 420
    },
    {
      "epoch": 0.2763496143958869,
      "grad_norm": 6.247781753540039,
      "learning_rate": 2.0254198531157307e-05,
      "loss": 0.6639,
      "step": 430
    },
    {
      "epoch": 0.2827763496143959,
      "grad_norm": 3.297088861465454,
      "learning_rate": 2.002271437415744e-05,
      "loss": 0.8108,
      "step": 440
    },
    {
      "epoch": 0.2892030848329049,
      "grad_norm": 4.798065662384033,
      "learning_rate": 1.979898987322333e-05,
      "loss": 0.8526,
      "step": 450
    },
    {
      "epoch": 0.29562982005141386,
      "grad_norm": 1.919455885887146,
      "learning_rate": 1.958260097304659e-05,
      "loss": 0.6229,
      "step": 460
    },
    {
      "epoch": 0.30205655526992287,
      "grad_norm": 1.4308955669403076,
      "learning_rate": 1.9373155368606583e-05,
      "loss": 0.6508,
      "step": 470
    },
    {
      "epoch": 0.30848329048843187,
      "grad_norm": 3.235403537750244,
      "learning_rate": 1.917028951268081e-05,
      "loss": 0.719,
      "step": 480
    },
    {
      "epoch": 0.3149100257069409,
      "grad_norm": 3.789013147354126,
      "learning_rate": 1.8973665961010272e-05,
      "loss": 0.8261,
      "step": 490
    },
    {
      "epoch": 0.3213367609254499,
      "grad_norm": 4.669565677642822,
      "learning_rate": 1.8782971010998232e-05,
      "loss": 0.7138,
      "step": 500
    },
    {
      "epoch": 0.3213367609254499,
      "eval_loss": 0.7016149759292603,
      "eval_runtime": 2071.9551,
      "eval_samples_per_second": 1.938,
      "eval_steps_per_second": 0.242,
      "step": 500
    },
    {
      "epoch": 0.3277634961439589,
      "grad_norm": 1.625959873199463,
      "learning_rate": 1.8597912596342e-05,
      "loss": 0.5865,
      "step": 510
    },
    {
      "epoch": 0.3341902313624679,
      "grad_norm": 2.102306842803955,
      "learning_rate": 1.841821840544761e-05,
      "loss": 0.684,
      "step": 520
    },
    {
      "epoch": 0.34061696658097684,
      "grad_norm": 3.288571357727051,
      "learning_rate": 1.8243634196048912e-05,
      "loss": 0.7021,
      "step": 530
    },
    {
      "epoch": 0.34704370179948585,
      "grad_norm": 5.985366344451904,
      "learning_rate": 1.8073922282301275e-05,
      "loss": 0.7659,
      "step": 540
    },
    {
      "epoch": 0.35347043701799485,
      "grad_norm": 5.2277374267578125,
      "learning_rate": 1.7908860173871274e-05,
      "loss": 0.7932,
      "step": 550
    },
    {
      "epoch": 0.35989717223650386,
      "grad_norm": 1.3959013223648071,
      "learning_rate": 1.7748239349298848e-05,
      "loss": 0.6179,
      "step": 560
    },
    {
      "epoch": 0.36632390745501286,
      "grad_norm": 1.568572759628296,
      "learning_rate": 1.759186414825121e-05,
      "loss": 0.6951,
      "step": 570
    },
    {
      "epoch": 0.37275064267352187,
      "grad_norm": 2.703009843826294,
      "learning_rate": 1.7439550769285394e-05,
      "loss": 0.6595,
      "step": 580
    },
    {
      "epoch": 0.3791773778920309,
      "grad_norm": 2.686929941177368,
      "learning_rate": 1.7291126361444983e-05,
      "loss": 0.7464,
      "step": 590
    },
    {
      "epoch": 0.3856041131105398,
      "grad_norm": 4.391377925872803,
      "learning_rate": 1.7146428199482245e-05,
      "loss": 0.7763,
      "step": 600
    },
    {
      "epoch": 0.3856041131105398,
      "eval_loss": 0.6970924735069275,
      "eval_runtime": 2072.0656,
      "eval_samples_per_second": 1.938,
      "eval_steps_per_second": 0.242,
      "step": 600
    },
    {
      "epoch": 0.39203084832904883,
      "grad_norm": 2.326108932495117,
      "learning_rate": 1.7005302933757236e-05,
      "loss": 0.5769,
      "step": 610
    },
    {
      "epoch": 0.39845758354755784,
      "grad_norm": 2.5596373081207275,
      "learning_rate": 1.6867605906952476e-05,
      "loss": 0.6271,
      "step": 620
    },
    {
      "epoch": 0.40488431876606684,
      "grad_norm": 2.044647455215454,
      "learning_rate": 1.6733200530681508e-05,
      "loss": 0.6365,
      "step": 630
    },
    {
      "epoch": 0.41131105398457585,
      "grad_norm": 3.8273749351501465,
      "learning_rate": 1.660195771588399e-05,
      "loss": 0.6517,
      "step": 640
    },
    {
      "epoch": 0.41773778920308485,
      "grad_norm": 5.60163688659668,
      "learning_rate": 1.6473755351607457e-05,
      "loss": 0.8288,
      "step": 650
    },
    {
      "epoch": 0.4241645244215938,
      "grad_norm": 1.5020720958709717,
      "learning_rate": 1.6348477827391983e-05,
      "loss": 0.5134,
      "step": 660
    },
    {
      "epoch": 0.4305912596401028,
      "grad_norm": 2.403029203414917,
      "learning_rate": 1.622601559501137e-05,
      "loss": 0.6507,
      "step": 670
    },
    {
      "epoch": 0.4370179948586118,
      "grad_norm": 2.1638033390045166,
      "learning_rate": 1.6106264765794776e-05,
      "loss": 0.6897,
      "step": 680
    },
    {
      "epoch": 0.4434447300771208,
      "grad_norm": 3.5750479698181152,
      "learning_rate": 1.5989126740164498e-05,
      "loss": 0.7767,
      "step": 690
    },
    {
      "epoch": 0.4498714652956298,
      "grad_norm": 4.3416643142700195,
      "learning_rate": 1.5874507866387543e-05,
      "loss": 0.8353,
      "step": 700
    },
    {
      "epoch": 0.4498714652956298,
      "eval_loss": 0.6944092512130737,
      "eval_runtime": 2071.3055,
      "eval_samples_per_second": 1.938,
      "eval_steps_per_second": 0.242,
      "step": 700
    },
    {
      "epoch": 0.45629820051413883,
      "grad_norm": 1.5566933155059814,
      "learning_rate": 1.5762319125856833e-05,
      "loss": 0.5786,
      "step": 710
    },
    {
      "epoch": 0.46272493573264784,
      "grad_norm": 2.4149281978607178,
      "learning_rate": 1.5652475842498527e-05,
      "loss": 0.6165,
      "step": 720
    },
    {
      "epoch": 0.4691516709511568,
      "grad_norm": 2.2418324947357178,
      "learning_rate": 1.5544897414149708e-05,
      "loss": 0.7059,
      "step": 730
    },
    {
      "epoch": 0.4755784061696658,
      "grad_norm": 2.360365152359009,
      "learning_rate": 1.543950706396996e-05,
      "loss": 0.7283,
      "step": 740
    },
    {
      "epoch": 0.4820051413881748,
      "grad_norm": 9.591903686523438,
      "learning_rate": 1.533623161014465e-05,
      "loss": 0.756,
      "step": 750
    },
    {
      "epoch": 0.4884318766066838,
      "grad_norm": 1.5238285064697266,
      "learning_rate": 1.5235001252310244e-05,
      "loss": 0.5173,
      "step": 760
    },
    {
      "epoch": 0.4948586118251928,
      "grad_norm": 1.8145612478256226,
      "learning_rate": 1.513574937328539e-05,
      "loss": 0.7235,
      "step": 770
    },
    {
      "epoch": 0.5012853470437018,
      "grad_norm": 6.679930210113525,
      "learning_rate": 1.503841235482809e-05,
      "loss": 0.778,
      "step": 780
    },
    {
      "epoch": 0.5077120822622108,
      "grad_norm": 4.697632312774658,
      "learning_rate": 1.4942929406261218e-05,
      "loss": 0.6914,
      "step": 790
    },
    {
      "epoch": 0.5141388174807198,
      "grad_norm": 23.678796768188477,
      "learning_rate": 1.4849242404917497e-05,
      "loss": 0.7631,
      "step": 800
    },
    {
      "epoch": 0.5141388174807198,
      "eval_loss": 0.6915412545204163,
      "eval_runtime": 2054.5188,
      "eval_samples_per_second": 1.954,
      "eval_steps_per_second": 0.244,
      "step": 800
    },
    {
      "epoch": 0.5205655526992288,
      "grad_norm": 1.8091096878051758,
      "learning_rate": 1.4757295747452435e-05,
      "loss": 0.5835,
      "step": 810
    },
    {
      "epoch": 0.5269922879177378,
      "grad_norm": 11.719610214233398,
      "learning_rate": 1.466703621116114e-05,
      "loss": 0.5847,
      "step": 820
    },
    {
      "epoch": 0.5334190231362468,
      "grad_norm": 12.259352684020996,
      "learning_rate": 1.4578412824513088e-05,
      "loss": 0.6902,
      "step": 830
    },
    {
      "epoch": 0.5398457583547558,
      "grad_norm": 6.002071857452393,
      "learning_rate": 1.4491376746189437e-05,
      "loss": 0.8066,
      "step": 840
    },
    {
      "epoch": 0.5462724935732648,
      "grad_norm": 4.4415788650512695,
      "learning_rate": 1.4405881151970742e-05,
      "loss": 0.8035,
      "step": 850
    },
    {
      "epoch": 0.5526992287917738,
      "grad_norm": 2.809725046157837,
      "learning_rate": 1.4321881128879943e-05,
      "loss": 0.5045,
      "step": 860
    },
    {
      "epoch": 0.5591259640102828,
      "grad_norm": 2.492537498474121,
      "learning_rate": 1.4239333576037017e-05,
      "loss": 0.6502,
      "step": 870
    },
    {
      "epoch": 0.5655526992287918,
      "grad_norm": 9.112749099731445,
      "learning_rate": 1.4158197111728084e-05,
      "loss": 0.7472,
      "step": 880
    },
    {
      "epoch": 0.5719794344473008,
      "grad_norm": 8.093812942504883,
      "learning_rate": 1.4078431986233807e-05,
      "loss": 0.7687,
      "step": 890
    },
    {
      "epoch": 0.5784061696658098,
      "grad_norm": 5.906955718994141,
      "learning_rate": 1.4e-05,
      "loss": 0.8097,
      "step": 900
    },
    {
      "epoch": 0.5784061696658098,
      "eval_loss": 0.6920759677886963,
      "eval_runtime": 2059.2573,
      "eval_samples_per_second": 1.95,
      "eval_steps_per_second": 0.244,
      "step": 900
    },
    {
      "epoch": 0.5848329048843187,
      "grad_norm": 3.7036187648773193,
      "learning_rate": 1.392286442676771e-05,
      "loss": 0.5981,
      "step": 910
    },
    {
      "epoch": 0.5912596401028277,
      "grad_norm": 2.2612545490264893,
      "learning_rate": 1.3846989941311527e-05,
      "loss": 0.6368,
      "step": 920
    },
    {
      "epoch": 0.5976863753213367,
      "grad_norm": 3.2522637844085693,
      "learning_rate": 1.3772342551463013e-05,
      "loss": 0.7175,
      "step": 930
    },
    {
      "epoch": 0.6041131105398457,
      "grad_norm": 3.650160551071167,
      "learning_rate": 1.3698889534122285e-05,
      "loss": 0.7327,
      "step": 940
    },
    {
      "epoch": 0.6105398457583547,
      "grad_norm": 5.433759689331055,
      "learning_rate": 1.362659937498405e-05,
      "loss": 0.7789,
      "step": 950
    },
    {
      "epoch": 0.6169665809768637,
      "grad_norm": 1.8532990217208862,
      "learning_rate": 1.3555441711725959e-05,
      "loss": 0.56,
      "step": 960
    },
    {
      "epoch": 0.6233933161953727,
      "grad_norm": 4.4467267990112305,
      "learning_rate": 1.3485387280426646e-05,
      "loss": 0.6742,
      "step": 970
    },
    {
      "epoch": 0.6298200514138818,
      "grad_norm": 2.582289218902588,
      "learning_rate": 1.3416407864998738e-05,
      "loss": 0.6919,
      "step": 980
    },
    {
      "epoch": 0.6362467866323908,
      "grad_norm": 2.943679094314575,
      "learning_rate": 1.3348476249438293e-05,
      "loss": 0.7214,
      "step": 990
    },
    {
      "epoch": 0.6426735218508998,
      "grad_norm": 4.5084357261657715,
      "learning_rate": 1.3281566172707193e-05,
      "loss": 0.8092,
      "step": 1000
    },
    {
      "epoch": 0.6426735218508998,
      "eval_loss": 0.6880782246589661,
      "eval_runtime": 2070.9694,
      "eval_samples_per_second": 1.939,
      "eval_steps_per_second": 0.242,
      "step": 1000
    },
    {
      "epoch": 0.6491002570694088,
      "grad_norm": 1.4821140766143799,
      "learning_rate": 1.3215652286078603e-05,
      "loss": 0.5817,
      "step": 1010
    },
    {
      "epoch": 0.6555269922879178,
      "grad_norm": 2.549842357635498,
      "learning_rate": 1.3150710112788139e-05,
      "loss": 0.6561,
      "step": 1020
    },
    {
      "epoch": 0.6619537275064268,
      "grad_norm": 3.0382683277130127,
      "learning_rate": 1.3086716009844873e-05,
      "loss": 0.6968,
      "step": 1030
    },
    {
      "epoch": 0.6683804627249358,
      "grad_norm": 2.620300769805908,
      "learning_rate": 1.3023647131866887e-05,
      "loss": 0.7439,
      "step": 1040
    },
    {
      "epoch": 0.6748071979434447,
      "grad_norm": 5.917168140411377,
      "learning_rate": 1.296148139681572e-05,
      "loss": 0.7724,
      "step": 1050
    },
    {
      "epoch": 0.6812339331619537,
      "grad_norm": 1.8844785690307617,
      "learning_rate": 1.2900197453512974e-05,
      "loss": 0.5334,
      "step": 1060
    },
    {
      "epoch": 0.6876606683804627,
      "grad_norm": 2.170722484588623,
      "learning_rate": 1.2839774650830604e-05,
      "loss": 0.6288,
      "step": 1070
    },
    {
      "epoch": 0.6940874035989717,
      "grad_norm": 3.4436933994293213,
      "learning_rate": 1.2780193008453874e-05,
      "loss": 0.7303,
      "step": 1080
    },
    {
      "epoch": 0.7005141388174807,
      "grad_norm": 3.076108694076538,
      "learning_rate": 1.2721433189123035e-05,
      "loss": 0.7247,
      "step": 1090
    },
    {
      "epoch": 0.7069408740359897,
      "grad_norm": 3.610288381576538,
      "learning_rate": 1.266347647226607e-05,
      "loss": 0.8528,
      "step": 1100
    },
    {
      "epoch": 0.7069408740359897,
      "eval_loss": 0.6862455606460571,
      "eval_runtime": 2058.2983,
      "eval_samples_per_second": 1.951,
      "eval_steps_per_second": 0.244,
      "step": 1100
    },
    {
      "epoch": 0.7133676092544987,
      "grad_norm": 1.8582607507705688,
      "learning_rate": 1.2606304728940948e-05,
      "loss": 0.5906,
      "step": 1110
    },
    {
      "epoch": 0.7197943444730077,
      "grad_norm": 2.0387158393859863,
      "learning_rate": 1.2549900398011132e-05,
      "loss": 0.6167,
      "step": 1120
    },
    {
      "epoch": 0.7262210796915167,
      "grad_norm": 2.7135140895843506,
      "learning_rate": 1.2494246463483319e-05,
      "loss": 0.7358,
      "step": 1130
    },
    {
      "epoch": 0.7326478149100257,
      "grad_norm": 3.0026471614837646,
      "learning_rate": 1.2439326432940939e-05,
      "loss": 0.6755,
      "step": 1140
    },
    {
      "epoch": 0.7390745501285347,
      "grad_norm": 5.428432941436768,
      "learning_rate": 1.2385124317011359e-05,
      "loss": 0.829,
      "step": 1150
    },
    {
      "epoch": 0.7455012853470437,
      "grad_norm": 1.2299927473068237,
      "learning_rate": 1.2331624609808773e-05,
      "loss": 0.6144,
      "step": 1160
    },
    {
      "epoch": 0.7519280205655527,
      "grad_norm": 2.1182336807250977,
      "learning_rate": 1.227881227029841e-05,
      "loss": 0.6805,
      "step": 1170
    },
    {
      "epoch": 0.7583547557840618,
      "grad_norm": 3.291900634765625,
      "learning_rate": 1.222667270453122e-05,
      "loss": 0.7181,
      "step": 1180
    },
    {
      "epoch": 0.7647814910025706,
      "grad_norm": 3.135190486907959,
      "learning_rate": 1.2175191748701416e-05,
      "loss": 0.7282,
      "step": 1190
    },
    {
      "epoch": 0.7712082262210797,
      "grad_norm": 4.4596052169799805,
      "learning_rate": 1.2124355652982138e-05,
      "loss": 0.7829,
      "step": 1200
    },
    {
      "epoch": 0.7712082262210797,
      "eval_loss": 0.684579074382782,
      "eval_runtime": 2028.704,
      "eval_samples_per_second": 1.979,
      "eval_steps_per_second": 0.247,
      "step": 1200
    }
  ],
  "logging_steps": 10,
  "max_steps": 1200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7105050809903514e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
